#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Copyright (C) 2019 Alvaro del Castillo
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335, USA.
#
# Authors:
#     Alvaro del Castillo <alvaro.delcastillo@gmail.com>
#


import argparse
import logging
import sys

import numpy as np
import pandas as pd

import dogbreed

DOGBREED_USAGE_MSG = \
    """%(prog)s [-g] [<args>] | --help | --version"""

DOGBREED_DESC_MSG = \
    """Detect dog breed using deep learning."""

DOGBREED_EPILOG_MSG = \
    """Run '%(prog)s --help' to show the help for using the program."""

DOGBREED_VERSION_MSG = \
    """%(prog)s """ + dogbreed.__version__


# Logging formats
DOGBREED_LOG_FORMAT = "[%(asctime)s] - %(message)s"
DOGBREED_DEBUG_LOG_FORMAT = "[%(asctime)s - %(name)s - %(levelname)s] - %(message)s"

# Pre-trained model to be used
RESNET_DIR = "models/resnet50"
RESNET_H5 = RESNET_DIR + "/resnet50_weights_tf_dim_ordering_tf_kernels.h5"
RESNET_JSON = RESNET_DIR + "/imagenet_class_index.json"

IMAGE_DIR_TRAIN = "images/train/"
IMAGE_DIR_TEST = "images/test/"


def configure_logging(debug=False):
    """Configure MyDogBreed logging
    The function configures the log messages produced by MyDogBreed.
    By default, log messages are sent to stderr. Set the parameter
    `debug` to activate the debug mode.
    :param debug: set the debug mode
    """
    if not debug:
        logging.basicConfig(level=logging.INFO,
                            format=DOGBREED_LOG_FORMAT)
        logging.getLogger('requests').setLevel(logging.WARNING)
        logging.getLogger('urrlib3').setLevel(logging.WARNING)
    else:
        logging.basicConfig(level=logging.DEBUG,
                            format=DOGBREED_DEBUG_LOG_FORMAT)


def parse_args():
    """Parse command line arguments"""

    parser = argparse.ArgumentParser(usage=DOGBREED_USAGE_MSG,
                                     description=DOGBREED_DESC_MSG,
                                     epilog=DOGBREED_EPILOG_MSG,
                                     formatter_class=argparse.RawDescriptionHelpFormatter,
                                     add_help=False)

    parser.add_argument('-h', '--help', action='help',
                        help=argparse.SUPPRESS)
    parser.add_argument('-v', '--version', action='version',
                        version=DOGBREED_VERSION_MSG,
                        help=argparse.SUPPRESS)
    parser.add_argument('-g', '--debug', dest='debug',
                        action='store_true',
                        help=argparse.SUPPRESS)

    # if len(sys.argv) == 1:
    #     parser.print_help()
    #     sys.exit(1)

    return parser.parse_args()

def kaggle_sample_ml():
    pass

def kaggle_digit_dl():
    # Detecting hand written digits
    # A new model is created from scratch
    # The model can be improved changing: number of layers,
    # kernel_size or filter in the convolution layers
    # Download test data from:
    # https://www.kaggle.com/c/digit-recognizer/download/test.csv
    #

    from sklearn.model_selection import train_test_split
    from tensorflow.python import keras
    from tensorflow.python.keras.models import Sequential
    from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout

    DIR_TRAIN = "images/digits/train/"
    # DIR_TEST = "images/digits/test/"

    img_rows, img_cols = 28, 28
    num_classes = 10

    def data_prep(raw):
        out_y = keras.utils.to_categorical(raw.label, num_classes)

        num_images = raw.shape[0]
        x_as_array = raw.values[:, 1:]
        x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)
        out_x = x_shaped_array / 255
        return out_x, out_y

    train_file = DIR_TRAIN + "train.csv"
    raw_data = pd.read_csv(train_file)

    x, y = data_prep(raw_data)

    # Creating a new sequential neural model
    model = Sequential()
    model.add(Conv2D(20, kernel_size=(3, 3),
                     activation='relu',
                     input_shape=(img_rows, img_cols, 1)))
    model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))
    model.add(Flatten())
    # Helper layer than improve the predictions
    model.add(Dense(128, activation='relu'))
    # Output layer, with num_classes predictions
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(loss=keras.losses.categorical_crossentropy,
                  optimizer='adam',
                  metrics=['accuracy'])
    # x training data, y predictions
    model.fit(x, y,
              batch_size=128,
              epochs=2,
              validation_split=0.2)

def kaggle_sample_dl():
    # For deep learning we must to cover
    # Howto to use pre created models
    # Howto use transfer learning to reuse models in new similar topics
    # Howto create new models
    from os.path import join

    img_paths = [join(IMAGE_DIR_TRAIN, filename) for filename in
                 ['0246f44bb123ce3f91c939861eb97fb7.jpg',
                  '84728e78632c0910a69d33f82e62638c.jpg',
                  '8825e914555803f4c67b26593c9d5aff.jpg',
                  '91a5e8db15bccfb6cfa2df5e8b95ec03.jpg']]

    img_paths_mina = ["images/mina/mina1.jpg"]

    from tensorflow.python.keras.applications.resnet50 import preprocess_input
    from tensorflow.python.keras.preprocessing.image import load_img, img_to_array

    image_size = 224

    def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):
        imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]
        img_array = np.array([img_to_array(img) for img in imgs])
        output = preprocess_input(img_array)
        return output

    from tensorflow.python.keras.applications import ResNet50

    my_model = ResNet50(weights=RESNET_H5)
    test_data = read_and_prep_images(img_paths)
    preds = my_model.predict(test_data)

    from learntools.deep_learning.decode_predictions import decode_predictions
    from PIL import Image

    most_likely_labels = decode_predictions(preds, top=3, class_list_path=RESNET_JSON)

    for i, img_path in enumerate(img_paths):
        Image.open(img_path).show()
        print(most_likely_labels[i])


def main():
    args = parse_args()

    configure_logging(args.debug)

    logging.info("Starting MyDogBreed magic.")

    # Load the image with the dog
    # Load the prediction model
    # Predict the breed and show it visually

    # kaggle_sample_dl()
    kaggle_digit_dl()

    logging.info("Breed detection finished.")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        s = "\n\nReceived Ctrl-C or other break signal. Exiting.\n"
        sys.stderr.write(s)
        sys.exit(0)